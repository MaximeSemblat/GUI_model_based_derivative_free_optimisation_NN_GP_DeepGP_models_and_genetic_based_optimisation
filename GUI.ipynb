{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2388065",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyqt6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134c6aac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install pyqt6-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3e1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install PySide6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1caf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10732e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be3a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gpflux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "801dcf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from sklearn.model_selection import train_test_split\n",
    "x = loadtxt(\"x14.txt\")\n",
    "y = loadtxt(\"y14.txt\")\n",
    "t = loadtxt(\"t14.txt\")\n",
    "\n",
    "x_A2O = x[0:32,:]\n",
    "x_Bardenpho = x[32:64,:]\n",
    "x_Johannesburg = x[64:96,:]\n",
    "x_UCT = x[96:128,:]\n",
    "\n",
    "y_A2O = y[0:32,:]\n",
    "y_Bardenpho =y[32:64,:]\n",
    "y_Johannesburg = y[64:96,:]\n",
    "y_UCT = y[96:128,:]\n",
    "\n",
    "t_A2O = t[0:32]\n",
    "t_Bardenpho = t[32:64]\n",
    "t_Johannesburg = t[64:96]\n",
    "t_UCT = t[96:128]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_train_A2O, x_test_A2O, x_train_Bardenpho, x_test_Bardenpho, x_train_Johannesburg, x_test_Johannesburg, x_train_UCT, x_test_UCT, y_train_A2O, y_test_A2O, y_train_Bardenpho, y_test_Bardenpho, y_train_Johannesburg,y_test_Johannesburg, y_train_UCT, y_test_UCT, t_train_A2O, t_test_A2O, t_train_Bardenpho, t_test_Bardenpho, t_train_Johannesburg,t_test_Johannesburg, t_train_UCT, t_test_UCT,= train_test_split(x_A2O,x_Bardenpho,x_Johannesburg,x_UCT,y_A2O,y_Bardenpho,y_Johannesburg,y_UCT,t_A2O,t_Bardenpho,t_Johannesburg,t_UCT,train_size=0.75)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "            \n",
    "scaler_A2O = StandardScaler()\n",
    "#normalise x_train\n",
    "x_train_A2O_ = scaler_A2O.fit_transform(x_train_A2O)\n",
    "x_train_A2O_mean, x_train_A2O_std = scaler_A2O.mean_,scaler_A2O.scale_\n",
    "# normalise x_test using training moments\n",
    "x_test_A2O_ = (x_test_A2O - x_train_A2O_mean) / x_train_A2O_std\n",
    "\n",
    "scaler_Johannesburg = StandardScaler()\n",
    "#normalise x_train\n",
    "x_train_Johannesburg_ = scaler_Johannesburg.fit_transform(x_train_Johannesburg)\n",
    "x_train_Johannesburg_mean, x_train_Johannesburg_std = scaler_Johannesburg.mean_ ,scaler_Johannesburg.scale_\n",
    "# normalise x_test using training moments\n",
    "x_test_Johannesburg_ = (x_test_Johannesburg - x_train_Johannesburg_mean) / x_train_Johannesburg_std\n",
    "\n",
    "scaler_Bardenpho = StandardScaler()\n",
    "#normalise x_train\n",
    "x_train_Bardenpho_ = scaler_Bardenpho.fit_transform(x_train_Bardenpho)\n",
    "x_train_Bardenpho_mean, x_train_Bardenpho_std = scaler_Bardenpho.mean_,scaler_Bardenpho.scale_\n",
    "# normalise x_test using training moments\n",
    "x_test_Bardenpho_ = (x_test_Bardenpho - x_train_Bardenpho_mean) / x_train_Bardenpho_std\n",
    "\n",
    "scaler_UCT = StandardScaler()\n",
    "#normalise x_train\n",
    "x_train_UCT_ = scaler_UCT.fit_transform(x_train_UCT)\n",
    "x_train_UCT_mean, x_train_UCT_std = scaler_UCT.mean_,scaler_UCT.scale_\n",
    "# normalise x_test using training moments\n",
    "x_test_UCT_ = (x_test_UCT - x_train_UCT_mean) / x_train_UCT_std\n",
    "            \n",
    "scaler_Johannesburg_y = StandardScaler()\n",
    "# normalise y_train only on converged data\n",
    "y_train_Johannesburg_con = y_train_Johannesburg[t_train_Johannesburg.ravel() == 1, :]\n",
    "scaler_Johannesburg_y.fit(y_train_Johannesburg_con)\n",
    "y_train_Johannesburg_mean, y_train_Johannesburg_std = scaler_Johannesburg_y.mean_, scaler_Johannesburg_y.scale_\n",
    "y_train_Johannesburg_ = (y_train_Johannesburg - y_train_Johannesburg_mean) / y_train_Johannesburg_std\n",
    "# normalise y_test using training moments\n",
    "y_test_Johannesburg_ = (y_test_Johannesburg - y_train_Johannesburg_mean) / y_train_Johannesburg_std\n",
    "\n",
    "scaler_Bardenpho_y = StandardScaler()\n",
    "# normalise y_train only on converged data\n",
    "y_train_Bardenpho_con = y_train_Bardenpho[t_train_Bardenpho.ravel() == 1, :]\n",
    "scaler_Bardenpho_y.fit(y_train_Bardenpho_con)\n",
    "y_train_Bardenpho_mean, y_train_Bardenpho_std = scaler_Bardenpho_y.mean_, scaler_Bardenpho_y.scale_\n",
    "y_train_Bardenpho_ = (y_train_Bardenpho - y_train_Bardenpho_mean) / y_train_Bardenpho_std\n",
    "# normalise y_test using training moments\n",
    "y_test_Bardenpho_ = (y_test_Bardenpho - y_train_Bardenpho_mean) / y_train_Bardenpho_std\n",
    "\n",
    "scaler_UCT_y = StandardScaler()\n",
    "# normalise y_train only on converged data\n",
    "y_train_UCT_con = y_train_UCT[t_train_UCT.ravel() == 1, :]\n",
    "scaler_UCT_y.fit(y_train_UCT_con)\n",
    "y_train_UCT_mean, y_train_UCT_std = scaler_UCT_y.mean_, scaler_UCT_y.scale_\n",
    "y_train_UCT_ = (y_train_UCT - y_train_UCT_mean) / y_train_UCT_std\n",
    "# normalise y_test using training moments\n",
    "y_test_UCT_ = (y_test_UCT - y_train_UCT_mean) / y_train_UCT_std\n",
    "\n",
    "scaler_A2O_y = StandardScaler()\n",
    "# normalise y_train only on converged data\n",
    "y_train_A2O_con = y_train_A2O[t_train_A2O.ravel() == 1, :]\n",
    "scaler_A2O_y.fit(y_train_A2O_con)\n",
    "y_train_A2O_mean, y_train_A2O_std = scaler_A2O_y.mean_, scaler_A2O_y.scale_\n",
    "y_train_A2O_ = (y_train_A2O - y_train_A2O_mean) / y_train_A2O_std\n",
    "# normalise y_test using training moments\n",
    "y_test_A2O_ = (y_test_A2O - y_train_A2O_mean) / y_train_A2O_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94febc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "626f76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train_A2O_gpc = t_train_A2O\n",
    "t_train_Bardenpho_gpc = t_train_Bardenpho\n",
    "t_train_Johannesburg_gpc = t_train_Johannesburg\n",
    "t_train_UCT_gpc = t_train_UCT\n",
    "\n",
    "t_test_A2O_gpc = t_test_A2O\n",
    "t_test_Bardenpho_gpc = t_test_Bardenpho\n",
    "t_test_Johannesburg_gpc = t_test_Johannesburg\n",
    "t_test_UCT_gpc = t_test_UCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aacd09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train_A2O_ = t_train_A2O.reshape(-1 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35d0e160",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train_Bardenpho_ = t_train_Bardenpho.reshape(-1 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "118a82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train_Johannesburg_ = t_train_Johannesburg.reshape(-1 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "813a9a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train_UCT_ = t_train_UCT.reshape(-1 , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2edc9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_A2O_ = t_test_A2O.reshape(-1 , 1)\n",
    "t_test_A2O_ = torch.from_numpy(t_test_A2O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5d68c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_Bardenpho_ = t_test_Bardenpho.reshape(-1 , 1)\n",
    "t_test_Bardenpho_ =torch.from_numpy(t_test_Bardenpho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb7ee6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_Johannesburg_ = t_test_Johannesburg.reshape(-1 , 1)\n",
    "t_test_Johannesburg_ =torch.from_numpy(t_test_Johannesburg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7adf039",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_UCT_ = t_test_UCT.reshape(-1 , 1)\n",
    "t_test_UCT_ =torch.from_numpy(t_test_UCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cb8f0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef9001db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PySide6 import QtWidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "370b07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ui_GUI_dev_V29 import Ui_MainWindow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0863a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN_and_GP import NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a57ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN_and_GP import GPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6114aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from NN_and_GP import GPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d96c7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimisation import OptimisationProblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7361070",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b0cb736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from PySide6.QtGui import QGuiApplication\n",
    "from PySide6.QtWidgets import QApplication, QGridLayout, QWidget, QMainWindow\n",
    "from matplotlib.backends.backend_qtagg import FigureCanvasQTAgg as FigureCanvas\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class MainWindow(QtWidgets.QMainWindow):\n",
    "    def __init__(self):\n",
    "        QtWidgets.QMainWindow.__init__(self)\n",
    "        self.ui = Ui_MainWindow()\n",
    "        self.ui.setupUi(self)\n",
    "        \n",
    "        self.ui.pushButton_ReLu.clicked.connect(self.on_clicked_ReLu)\n",
    "        self.ui.pushButton_Leaky_ReLu.clicked.connect(self.on_clicked_Leaky_ReLu)\n",
    "        self.ui.pushButton_Swish.clicked.connect(self.on_clicked_swish)\n",
    "        self.ui.pushButton_Softplus.clicked.connect(self.on_clicked_softplus)\n",
    "        self.ui.pushButton_Sigmoid.clicked.connect(self.on_clicked_Sigmoid)\n",
    "        self.ui.pushButton_Serf.clicked.connect(self.on_clicked_serf)\n",
    "        self.ui.pushButton_RQ.clicked.connect(self.on_clicked_RQ)\n",
    "        self.ui.pushButton_show_results.clicked.connect(self.bar_chart)\n",
    "        self.ui.pushButton_Linear.clicked.connect(self.on_clicked_Linear)\n",
    "        self.ui.pushButton_RBF.clicked.connect(self.on_clicked_RBF)\n",
    "        self.ui.pushButton_Poly.clicked.connect(self.on_clicked_Poly)\n",
    "        self.ui.pushButton_ESS.clicked.connect(self.on_clicked_ESS)\n",
    "        self.ui.pushButton_Matern.clicked.connect(self.on_clicked_Matern)\n",
    "        self.ui.pushButton_two.clicked.connect(self.on_clicked_two)\n",
    "        self.ui.pushButton_Three.clicked.connect(self.on_clicked_three)\n",
    "        self.ui.pushButton_four.clicked.connect(self.on_clicked_four)\n",
    "        self.ui.pushButton_Sum_RBF.clicked.connect(self.on_clicked_Sum_RBF)\n",
    "        self.ui.pushButton_Sum_RQ.clicked.connect(self.on_clicked_Sum_RQ)\n",
    "        self.ui.pushButton_GPC.clicked.connect(self.on_clicked_Classification)\n",
    "        self.ui.pushButton_Leaky_ReLu_cl.clicked.connect(self.on_clicked_Leaky_ReLu_cl)\n",
    "        self.ui.pushButton_Relu_cl.clicked.connect(self.on_clicked_ReLu_cl)\n",
    "        self.ui.pushButton_Serf_cl.clicked.connect(self.on_clicked_Serf_cl)\n",
    "        self.ui.pushButton_Swish_cl.clicked.connect(self.on_clicked_Swish_cl)\n",
    "        self.ui.pushButton_Soft_Plus_cl.clicked.connect(self.on_clicked_Soft_Plus_cl)\n",
    "        self.ui.pushButton_opti_ReLu.clicked.connect(self.on_clicked_opti_ReLu)\n",
    "        self.ui.pushButton_opti_Leaky_ReLu.clicked.connect(self.on_clicked_opti_Leaky_ReLu)\n",
    "        self.ui.pushButton_opti_Swish.clicked.connect(self.on_clicked_opti_Swish)\n",
    "        self.ui.pushButton_opti_Softplus.clicked.connect(self.on_clicked_opti_Softplus)\n",
    "        self.ui.pushButton_opti_Sigmoid.clicked.connect(self.on_clicked_opti_Sigmoid)\n",
    "        self.ui.pushButton_opti_Serf.clicked.connect(self.on_clicked_opti_Serf)\n",
    "        self.ui.pushButton_opti_Two.clicked.connect(self.on_clicked_opti_Two)\n",
    "        self.ui.pushButton_opti_Three.clicked.connect(self.on_clicked_opti_Three)\n",
    "        self.ui.pushButton_opti_Four.clicked.connect(self.on_clicked_opti_Four)\n",
    "        self.ui.pushButton_A2O.clicked.connect(self.on_clicked_A2O)       \n",
    "        self.ui.pushButton_Bardenpho.clicked.connect(self.on_clicked_Bardenpho)\n",
    "        self.ui.pushButton_Johannesburg.clicked.connect(self.on_clicked_Johannesburg)\n",
    "        self.ui.pushButton_UCT.clicked.connect(self.on_clicked_UCT)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # losses intialisation \n",
    "        self.loss_RQ = 0\n",
    "        self.loss_ReLu = 0\n",
    "        self.loss_Leaky_ReLu = 0\n",
    "        self.loss_swish = 0\n",
    "        self.loss_softplus = 0\n",
    "        self.loss_serf = 0\n",
    "        self.loss_Linear = 0\n",
    "        self.loss_RBF = 0\n",
    "        self.loss_Poly = 0\n",
    "        self.loss_ESS = 0\n",
    "        self.loss_Matern = 0\n",
    "        self.loss_Sum_RBF = 0\n",
    "        self.loss_Sum_RQ = 0\n",
    "        self.loss_two = 0\n",
    "        self.loss_three = 0\n",
    "        self.loss_four = 0\n",
    "        self.loss_Sigmoid = 0\n",
    "        \n",
    "        self.price_biogas = 0.305 #per meter cubed in USD \n",
    "        self.price_sludge_TP = 1.84 #USD per kg\n",
    "        self.price_sludge_TN = 1.19 #USD per kg \n",
    "        \n",
    "    def on_clicked_A2O(self):\n",
    "        \n",
    "        self.x_train_ = x_train_A2O_\n",
    "        self.x_train_mean = x_train_A2O_mean\n",
    "        self.x_train_std = x_train_A2O_std\n",
    "        \n",
    "        self.t_train = t_train_A2O_\n",
    "        self.t_train_gpc = t_train_A2O_gpc\n",
    "        \n",
    "        self.t_test = t_test_A2O_\n",
    "        self.t_test_gpc = t_test_A2O_gpc\n",
    "        \n",
    "        self.y_train_ = y_train_A2O_\n",
    "        self.y_train_mean = y_train_A2O_mean\n",
    "        self.y_train_std = y_train_A2O_std\n",
    "        \n",
    "        self.x_test_ = x_test_A2O_\n",
    "        self.y_test_ = y_test_A2O_\n",
    "        \n",
    "        self.scaler= scaler_A2O \n",
    "        self.scaler_y = scaler_A2O_y\n",
    "        \n",
    "    def on_clicked_Johannesburg(self):\n",
    "        \n",
    "        self.x_train_ = x_train_Johannesburg_\n",
    "        self.x_train_mean = x_train_Johannesburg_mean\n",
    "        self.x_train_std = x_train_Johannesburg_std\n",
    "        \n",
    "        self.t_train = t_train_Johannesburg_\n",
    "        self.t_train_gpc = t_train_Johannesburg_gpc\n",
    "        \n",
    "        self.t_test = t_test_Johannesburg_\n",
    "        self.t_test_gpc = t_test_Johannesburg_gpc\n",
    "        \n",
    "        self.y_train_ = y_train_Johannesburg_\n",
    "        self.y_train_mean = y_train_Johannesburg_mean\n",
    "        self.y_train_std = y_train_Johannesburg_std\n",
    "        \n",
    "        self.x_test_ = x_test_Johannesburg_\n",
    "        self.y_test_ = y_test_Johannesburg_\n",
    "        \n",
    "        self.scaler= scaler_Johannesburg \n",
    "        self.scaler_y = scaler_Johannesburg_y\n",
    "    \n",
    "    def on_clicked_Bardenpho(self):\n",
    "        \n",
    "        self.x_train_ = x_train_Bardenpho_\n",
    "        self.x_train_mean = x_train_Bardenpho_mean\n",
    "        self.x_train_std = x_train_Bardenpho_std\n",
    "        \n",
    "        self.t_train = t_train_Bardenpho_\n",
    "        self.t_train_gpc = t_train_Bardenpho_gpc\n",
    "        \n",
    "        self.t_test = t_test_Bardenpho_\n",
    "        self.t_test_gpc = t_test_Bardenpho_gpc\n",
    "        \n",
    "        self.y_train_ = y_train_Bardenpho_\n",
    "        self.y_train_mean = y_train_Bardenpho_mean\n",
    "        self.y_train_std = y_train_Bardenpho_std\n",
    "        \n",
    "        self.x_test_ = x_test_Bardenpho_\n",
    "        self.y_test_ = y_test_Bardenpho_\n",
    "        \n",
    "        self.scaler= scaler_Bardenpho \n",
    "        self.scaler_y = scaler_Bardenpho_y\n",
    "        \n",
    "    def on_clicked_UCT(self):\n",
    "            \n",
    "        self.x_train_ = x_train_UCT_\n",
    "        self.x_train_mean = x_train_UCT_mean\n",
    "        self.x_train_std = x_train_UCT_std\n",
    "        \n",
    "        self.t_train = t_train_UCT_\n",
    "        self.t_train_gpc = t_train_UCT_gpc\n",
    "        \n",
    "        self.t_test = t_test_UCT_\n",
    "        self.t_test_gpc = t_test_UCT_gpc\n",
    "        \n",
    "        self.y_train_ = y_train_UCT_\n",
    "        self.y_train_mean = y_train_UCT_mean\n",
    "        self.y_train_std = y_train_UCT_std\n",
    "        \n",
    "        self.x_test_ = x_test_UCT_\n",
    "        self.y_test_ = y_test_UCT_\n",
    "        \n",
    "        self.scaler= scaler_UCT \n",
    "        self.scaler_y = scaler_UCT_y    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    def on_clicked_Leaky_ReLu_cl(self):\n",
    "        nn=NN([2,5,10,1], activation ='leaky relu', is_classifier=True)\n",
    "        nn.fit(self.x_train_,self.t_train,batch_size=1,epochs=1000, learning_rate=1e-2, weight_decay=0.0, loss_func=torch.nn.MSELoss(), iprint=True)\n",
    "        y_predict_cl, cl =nn.predict(self.x_test_,return_proba=False, return_class=True)\n",
    "        cl  = torch.from_numpy(cl)\n",
    "        loss = mse_loss(self.t_test, cl)\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(loss.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std    \n",
    "        predict_1 , predict = nn.predict(x_input,return_proba=False, return_class=True)\n",
    "        predict = predict.reshape(1,-1)\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "\n",
    "    def on_clicked_ReLu_cl(self):\n",
    "        nn=NN([2,5,10,1], activation ='relu', is_classifier=True)\n",
    "        nn.fit(self.x_train_,self.t_train,batch_size=1,epochs=1000, learning_rate=1e-2, weight_decay=0.0, loss_func=torch.nn.MSELoss(), iprint=True)\n",
    "        y_predict_cl, cl =nn.predict(self.x_test_,return_proba=False, return_class=True)\n",
    "        cl  = torch.from_numpy(cl)\n",
    "        loss = mse_loss(self.t_test, cl)\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(loss.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_test using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std    \n",
    "        predict_1 , predict = nn.predict(x_input,return_proba=False, return_class=True)\n",
    "        predict = predict.reshape(1,-1)\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_Serf_cl(self):\n",
    "        nn=NN([2,5,10,1], activation ='serf', is_classifier=True)\n",
    "        nn.fit(self.x_train_,self.t_train,batch_size=1,epochs=1000, learning_rate=1e-2, weight_decay=0.0, loss_func=torch.nn.MSELoss(), iprint=True)\n",
    "        y_predict_cl, cl =nn.predict(self.x_test_,return_proba=False, return_class=True)\n",
    "        cl  = torch.from_numpy(cl)\n",
    "        loss = mse_loss(self.t_test, cl)\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(loss.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_test using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std    \n",
    "        predict_1 , predict = nn.predict(x_input,return_proba=False, return_class=True)\n",
    "        predict = predict.reshape(1,-1)\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_Soft_Plus_cl(self):\n",
    "        nn=NN([2,5,10,1], activation ='softplus', is_classifier=True)\n",
    "        nn.fit(self.x_train_,self.t_train,batch_size=1,epochs=1000, learning_rate=1e-2, weight_decay=0.0, loss_func=torch.nn.MSELoss(), iprint=True)\n",
    "        y_predict_cl, cl =nn.predict(self.x_test_,return_proba=False, return_class=True)\n",
    "        cl  = torch.from_numpy(cl)\n",
    "        loss = mse_loss(self.t_test, cl)\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(loss.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_test using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std    \n",
    "        predict_1 , predict = nn.predict(x_input,return_proba=False, return_class=True)\n",
    "        predict = predict.reshape(1,-1)\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_Swish_cl(self):\n",
    "        nn=NN([2,5,10,1], activation ='swish', is_classifier=True)\n",
    "        nn.fit(self.x_train_,self.t_train,batch_size=1,epochs=1000, learning_rate=1e-2, weight_decay=0.0, loss_func=torch.nn.MSELoss(), iprint=True)\n",
    "        y_predict_cl, cl =nn.predict(self.x_test_,return_proba=False, return_class=True)\n",
    "        cl  = torch.from_numpy(cl)\n",
    "        loss = mse_loss(self.t_test, cl)\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(loss.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_test using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std    \n",
    "        predict_1 , predict = nn.predict(x_input,return_proba=False, return_class=True)\n",
    "        predict = predict.reshape(1,-1)\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_Classification(self):\n",
    "        gpc = GPC()\n",
    "        gpc.fit(self.x_train_,self.t_train_gpc,iprint=True)\n",
    "        t_predict_gpc ,t_class = gpc.predict(self.x_test_,return_class=True, threshold=0.5)\n",
    "        t_class= torch.from_numpy(t_class)\n",
    "        loss = mse_loss(torch.from_numpy(self.t_test_gpc),t_class[0,:])\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(loss.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std    \n",
    "        gpc , predict = gpc.predict(x_input,return_class=True, threshold=0.5)\n",
    "        predict = predict[0,:]\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_ReLu(self):\n",
    "        self.nn_ReLu = NN([2,5,10,12], activation ='relu', is_classifier=False)\n",
    "        self.nn_ReLu.fit(self.x_train_,self.y_train_,batch_size=1,epochs=1000, learning_rate=1e-2, weight_decay=0.0, loss_func=torch.nn.MSELoss(), iprint=True)\n",
    "        y_predict = torch.from_numpy(self.nn_ReLu.predict(self.x_test_))\n",
    "        self.loss_ReLu= mse_loss(y_predict,torch.from_numpy(self.y_test_))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_ReLu.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        predict = self.nn_ReLu.predict(x_input)\n",
    "        predict = (predict * self.y_train_std) + self.y_train_mean\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_opti_ReLu(self):\n",
    "        input_text_indiv= self.ui.lineEdit_num_indiv.text()\n",
    "        num_of_individuals = ast.literal_eval(input_text_indiv)\n",
    "        input_text_gen= self.ui.lineEdit_num_gen.text()\n",
    "        num_of_generations = ast.literal_eval(input_text_gen)\n",
    "        self.opti_ReLu = OptimisationProblem(self.nn_ReLu, model = 'NN')\n",
    "        result = self.opti_ReLu.solve(bounds =[(-1.8,1.8), (-1.8,1.8)], num_of_individuals = num_of_individuals, num_of_generations = num_of_generations )\n",
    "        result_array = np.array(result[1])\n",
    "        result_reshaped= result_array.reshape(1  ,-1)\n",
    "        true_result = self.scaler.inverse_transform(result_reshaped)\n",
    "        result_predict = np.array(result[-1])\n",
    "        result_predict_reshaped = result_predict.reshape(1,-1) \n",
    "        true_predict = self.scaler_y.inverse_transform(result_predict_reshaped)\n",
    "        true_objective = self.price_biogas*(true_predict[0,3]+true_predict[0,4])+self.price_sludge_TP*true_predict[0,8]+self.price_sludge_TN*true_predict[0,7]-(true_predict[0,9]+true_predict[0,10])\n",
    "        self.ui.label_results_opti.setText(\"The optimal individuals and objective function are: \" + str(true_result)+\", \" + str(true_objective))\n",
    "   \n",
    "    def on_clicked_Leaky_ReLu(self):\n",
    "        self.nn_Leaky_ReLu = NN([2,5,10,12], activation ='leaky relu', is_classifier=False)\n",
    "        self.nn_Leaky_ReLu.fit(self.x_train_,self.y_train_,batch_size=1,epochs=1000, learning_rate=1e-2, weight_decay=0.0, loss_func=torch.nn.MSELoss(), iprint=True)\n",
    "        y_predict = torch.from_numpy(self.nn_Leaky_ReLu.predict(self.x_test_))\n",
    "        self.loss_Leaky_ReLu= mse_loss(y_predict,torch.from_numpy(self.y_test_))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_Leaky_ReLu.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        predict = self.nn_Leaky_ReLu.predict(x_input)\n",
    "        predict = (predict * self.y_train_std) + self.y_train_mean\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_opti_Leaky_ReLu(self):\n",
    "        input_text_indiv= self.ui.lineEdit_num_indiv.text()\n",
    "        num_of_individuals = ast.literal_eval(input_text_indiv)\n",
    "        input_text_gen= self.ui.lineEdit_num_gen.text()\n",
    "        num_of_generations = ast.literal_eval(input_text_gen)\n",
    "        self.opti_Leaky_ReLu = OptimisationProblem(self.nn_Leaky_ReLu, model = 'NN')\n",
    "        result = self.opti_Leaky_ReLu.solve(bounds =[(-1.8,1.8), (-1.8,1.8)], num_of_individuals = num_of_individuals, num_of_generations = num_of_generations )\n",
    "        result_array = np.array(result[1])\n",
    "        result_reshaped= result_array.reshape(1  ,-1)\n",
    "        true_result = self.scaler.inverse_transform(result_reshaped)\n",
    "        result_predict = np.array(result[-1])\n",
    "        result_predict_reshaped = result_predict.reshape(1,-1) \n",
    "        true_predict = self.scaler_y.inverse_transform(result_predict_reshaped)\n",
    "        true_objective = self.price_biogas*(true_predict[0,3]+true_predict[0,4])+self.price_sludge_TP*true_predict[0,8]+self.price_sludge_TN*true_predict[0,7]-(true_predict[0,9]+true_predict[0,10])\n",
    "        self.ui.label_results_opti.setText(\"The optimal individuals and objective function are: \" + str(true_result)+\", \" + str(true_objective))\n",
    "                \n",
    "    def on_clicked_swish(self):\n",
    "        self.nn_Swish=NN([2,5,10,12], activation ='swish', is_classifier=False)\n",
    "        self.nn_Swish.fit(self.x_train_,self.y_train_,batch_size=1,epochs=1000, learning_rate=1e-2, weight_decay=0.0, loss_func=torch.nn.MSELoss(), iprint=True)\n",
    "        y_predict = torch.from_numpy(self.nn_Swish.predict(self.x_test_))\n",
    "        self.loss_swish= mse_loss(y_predict,torch.from_numpy(self.y_test_))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_swish.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        predict = self.nn_Swish.predict(x_input)\n",
    "        predict = (predict * self.y_train_std) + self.y_train_mean\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_opti_Swish(self):\n",
    "        input_text_indiv= self.ui.lineEdit_num_indiv.text()\n",
    "        num_of_individuals = ast.literal_eval(input_text_indiv)\n",
    "        input_text_gen= self.ui.lineEdit_num_gen.text()\n",
    "        num_of_generations = ast.literal_eval(input_text_gen)\n",
    "        self.opti_Swish = OptimisationProblem(self.nn_Swish, model = 'NN')\n",
    "        result = self.opti_Swish.solve(bounds =[(-1.8,1.8), (-1.8,1.8)], num_of_individuals = num_of_individuals, num_of_generations = num_of_generations )\n",
    "        result_array = np.array(result[1])\n",
    "        result_reshaped= result_array.reshape(1  ,-1)\n",
    "        true_result = self.scaler.inverse_transform(result_reshaped)\n",
    "        result_predict = np.array(result[-1])\n",
    "        result_predict_reshaped = result_predict.reshape(1,-1) \n",
    "        true_predict = self.scaler_y.inverse_transform(result_predict_reshaped)\n",
    "        true_objective = self.price_biogas*(true_predict[0,3]+true_predict[0,4])+self.price_sludge_TP*true_predict[0,8]+self.price_sludge_TN*true_predict[0,7]-(true_predict[0,9]+true_predict[0,10])\n",
    "        self.ui.label_results_opti.setText(\"The optimal individuals and objective function are: \" + str(true_result)+\", \" + str(true_objective))\n",
    "        \n",
    "    def on_clicked_softplus(self):\n",
    "        self.nn_Softplus = NN([2,5,10,12], activation ='softplus', is_classifier=False)\n",
    "        self.nn_Softplus.fit(self.x_train_,self.y_train_,batch_size=1,epochs=1000, learning_rate=1e-2, weight_decay=0.0, loss_func=torch.nn.MSELoss(), iprint=True)\n",
    "        y_predict = torch.from_numpy(self.nn_Softplus.predict(self.x_test_))\n",
    "        self.loss_softplus= mse_loss(y_predict,torch.from_numpy(self.y_test_))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_softplus.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        predict = self.nn_Softplus.predict(x_input)\n",
    "        predict = (predict * self.y_train_std) + self.y_train_mean\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "         \n",
    "    def on_clicked_opti_Softplus(self):\n",
    "        input_text_indiv= self.ui.lineEdit_num_indiv.text()\n",
    "        num_of_individuals = ast.literal_eval(input_text_indiv)\n",
    "        input_text_gen= self.ui.lineEdit_num_gen.text()\n",
    "        num_of_generations = ast.literal_eval(input_text_gen)\n",
    "        self.opti_Softplus = OptimisationProblem(self.nn_Softplus, model = 'NN')\n",
    "        result = self.opti_Softplus.solve(bounds =[(-1.8,1.8), (-1.8,1.8)], num_of_individuals = num_of_individuals, num_of_generations = num_of_generations )\n",
    "        result_array = np.array(result[1])\n",
    "        result_reshaped= result_array.reshape(1  ,-1)\n",
    "        true_result = self.scaler.inverse_transform(result_reshaped)\n",
    "        result_predict = np.array(result[-1])\n",
    "        result_predict_reshaped = result_predict.reshape(1,-1) \n",
    "        true_predict = self.scaler_y.inverse_transform(result_predict_reshaped)\n",
    "        true_objective = self.price_biogas*(true_predict[0,3]+true_predict[0,4])+self.price_sludge_TP*true_predict[0,8]+self.price_sludge_TN*true_predict[0,7]-(true_predict[0,9]+true_predict[0,10])\n",
    "        self.ui.label_results_opti.setText(\"The optimal individuals and objective function are: \" + str(true_result)+\", \" + str(true_objective))\n",
    "    \n",
    "    def on_clicked_Sigmoid(self):\n",
    "        self.nn_Sigmoid = NN([2,5,10,12], activation ='sigmoid', is_classifier=False)\n",
    "        self.nn_Sigmoid.fit(self.x_train_,self.y_train_,batch_size=1,epochs=1000, learning_rate=1e-2, weight_decay=0.0, loss_func=torch.nn.MSELoss(), iprint=True)\n",
    "        y_predict = torch.from_numpy(self.nn_Sigmoid.predict(self.x_test_))\n",
    "        self.loss_Sigmoid= mse_loss(y_predict,torch.from_numpy(self.y_test_))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_Sigmoid.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        predict = self.nn_Sigmoid.predict(x_input)\n",
    "        predict = (predict * self.y_train_std) + self.y_train_mean\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_opti_Sigmoid(self):\n",
    "        input_text_indiv= self.ui.lineEdit_num_indiv.text()\n",
    "        num_of_individuals = ast.literal_eval(input_text_indiv)\n",
    "        input_text_gen= self.ui.lineEdit_num_gen.text()\n",
    "        num_of_generations = ast.literal_eval(input_text_gen)\n",
    "        self.opti_Sigmoid = OptimisationProblem(self.nn_Sigmoid, model = 'NN')\n",
    "        result = self.opti_Sigmoid.solve(bounds =[(-1.8,1.8), (-1.8,1.8)], num_of_individuals = num_of_individuals, num_of_generations = num_of_generations )\n",
    "        result_array = np.array(result[1])\n",
    "        result_reshaped= result_array.reshape(1  ,-1)\n",
    "        true_result = self.scaler.inverse_transform(result_reshaped)\n",
    "        result_predict = np.array(result[-1])\n",
    "        result_predict_reshaped = result_predict.reshape(1,-1) \n",
    "        true_predict = self.scaler_y.inverse_transform(result_predict_reshaped)\n",
    "        true_objective = self.price_biogas*(true_predict[0,3]+true_predict[0,4])+self.price_sludge_TP*true_predict[0,8]+self.price_sludge_TN*true_predict[0,7]-(true_predict[0,9]+true_predict[0,10])\n",
    "        self.ui.label_results_opti.setText(\"The optimal individuals and objective function are: \" + str(true_result)+\", \" + str(true_objective))\n",
    "        \n",
    "    def on_clicked_serf(self):\n",
    "        self.nn_Serf = NN([2,5,10,12], activation ='serf', is_classifier=False)\n",
    "        self.nn_Serf.fit(self.x_train_,self.y_train_,batch_size=1,epochs=1000, learning_rate=1e-2, weight_decay=0.0, loss_func=torch.nn.MSELoss(), iprint=True)\n",
    "        y_predict = torch.from_numpy(self.nn_Serf.predict(self.x_test_))\n",
    "        self.loss_serf= mse_loss(y_predict,torch.from_numpy(self.y_test_))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_serf.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        predict = self.nn_Serf.predict(x_input)\n",
    "        predict = (predict * self.y_train_std) + self.y_train_mean\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_opti_Serf(self):\n",
    "        input_text_indiv= self.ui.lineEdit_num_indiv.text()\n",
    "        num_of_individuals = ast.literal_eval(input_text_indiv)\n",
    "        input_text_gen= self.ui.lineEdit_num_gen.text()\n",
    "        num_of_generations = ast.literal_eval(input_text_gen)\n",
    "        self.opti_Serf = OptimisationProblem(self.nn_Serf, model = 'NN')\n",
    "        result = self.opti_Serf.solve(bounds =[(-1.8,1.8), (-1.8,1.8)], num_of_individuals = num_of_individuals, num_of_generations = num_of_generations )\n",
    "        result_array = np.array(result[1])\n",
    "        result_reshaped= result_array.reshape(1  ,-1)\n",
    "        true_result = self.scaler.inverse_transform(result_reshaped)\n",
    "        result_predict = np.array(result[-1])\n",
    "        result_predict_reshaped = result_predict.reshape(1,-1) \n",
    "        true_predict = self.scaler_y.inverse_transform(result_predict_reshaped)\n",
    "        true_objective = self.price_biogas*(true_predict[0,3]+true_predict[0,4])+self.price_sludge_TP*true_predict[0,8]+self.price_sludge_TN*true_predict[0,7]-(true_predict[0,9]+true_predict[0,10])\n",
    "        self.ui.label_results_opti.setText(\"The optimal individuals and objective function are: \" + str(true_result)+\", \" + str(true_objective))\n",
    "        \n",
    "        \n",
    "    def on_clicked_RQ(self):\n",
    "        y_train_gp = self.y_train_[:,0]\n",
    "        y_test_gp =self.y_test_[:,0]\n",
    "        gp=GPR()\n",
    "        gp.__init__(kernel='RationalQuadratic', noise=2e-9,optimizer='fmin_l_bfgs_b',n_restarts_optimizer=10,porder=2)\n",
    "        gp.fit(self.x_train_,y_train_gp,iprint=True)\n",
    "        y_predict_gp, std_gp =gp.predict(self.x_test_,return_std=True, return_cov=False )\n",
    "        self.loss_RQ = mse_loss(torch.from_numpy(y_test_gp),torch.from_numpy(y_predict_gp))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_RQ.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        predict = gp.predict(x_input,return_std=False, return_cov=False )\n",
    "        predict = (predict * self.y_train_std[0]) + self.y_train_mean[0]\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_Linear(self):\n",
    "        y_train_gp = self.y_train_[:,0]\n",
    "        y_test_gp = self.y_test_[:,0]\n",
    "        gp=GPR()\n",
    "        gp.__init__(kernel='linear', noise=1e-10,optimizer='fmin_l_bfgs_b',n_restarts_optimizer=10, porder=2)\n",
    "        gp.fit(self.x_train_,y_train_gp,iprint=True)\n",
    "        y_predict_gp, std_gp =gp.predict(self.x_test_,return_std=True, return_cov=False )\n",
    "        self.loss_Linear = mse_loss(torch.from_numpy(y_test_gp),torch.from_numpy(y_predict_gp))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_Linear.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        predict = gp.predict(x_input,return_std=False, return_cov=False )\n",
    "        predict = (predict * self.y_train_std[0]) + self.y_train_mean[0]\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "      \n",
    "    def on_clicked_RBF(self):\n",
    "        y_train_gp = self.y_train_[:,0]\n",
    "        y_test_gp =self.y_test_[:,0]\n",
    "        gp=GPR()\n",
    "        gp.__init__(kernel='rbf', noise=1e-8,optimizer='fmin_l_bfgs_b',n_restarts_optimizer=10, porder=2)\n",
    "        gp.fit(self.x_train_,y_train_gp,iprint=True)\n",
    "        y_predict_gp, std_gp =gp.predict(self.x_test_,return_std=True, return_cov=False )\n",
    "        self.loss_RBF = mse_loss(torch.from_numpy(y_test_gp),torch.from_numpy(y_predict_gp))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_RBF.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_test using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        predict, std = gp.predict(x_input,return_std=True, return_cov=False )\n",
    "        predict = (predict * self.y_train_std[0]) + self.y_train_mean[0]\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_Poly(self):\n",
    "        y_train_gp = self.y_train_[:,0]\n",
    "        y_test_gp =self.y_test_[:,0]\n",
    "        gp=GPR()\n",
    "        gp.__init__(kernel='polynomial', noise=1.8108,optimizer='fmin_l_bfgs_b',n_restarts_optimizer=10, porder=2)\n",
    "        gp.fit(self.x_train_,y_train_gp,iprint=True)\n",
    "        y_predict_gp, std_gp =gp.predict(self.x_test_,return_std=True, return_cov=False )\n",
    "        self.loss_Poly = mse_loss(torch.from_numpy(y_test_gp),torch.from_numpy(y_predict_gp))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_Poly.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        predict = gp.predict(x_input,return_std=False, return_cov=False )\n",
    "        predict = (predict * self.y_train_std[0]) + self.y_train_mean[0]\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "      \n",
    "    def on_clicked_ESS(self):\n",
    "        y_train_gp = self.y_train_[:,0]\n",
    "        y_test_gp = self.y_test_[:,0]\n",
    "        gp=GPR()\n",
    "        gp.__init__(kernel='ExpSineSquared', noise=8,optimizer='fmin_l_bfgs_b',n_restarts_optimizer=10, porder=2)\n",
    "        gp.fit(self.x_train_,y_train_gp,iprint=True)\n",
    "        y_predict_gp, std_gp =gp.predict(self.x_test_,return_std=True, return_cov=False )\n",
    "        self.loss_ESS = mse_loss(torch.from_numpy(y_test_gp),torch.from_numpy(y_predict_gp))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_ESS.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        predict = gp.predict(x_input,return_std=False, return_cov=False )\n",
    "        predict = (predict * self.y_train_std[0]) + self.y_train_mean[0]\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "      \n",
    "    def on_clicked_Matern(self):\n",
    "        y_train_gp = self.y_train_[:,0]\n",
    "        y_test_gp = self.y_test_[:,0]\n",
    "        gp=GPR()\n",
    "        gp.__init__(kernel='Matern', noise=1e-10,optimizer='fmin_l_bfgs_b',n_restarts_optimizer=10, porder=2)\n",
    "        gp.fit(self.x_train_,y_train_gp,iprint=True)\n",
    "        y_predict_gp, std_gp =gp.predict(self.x_test_,return_std=True, return_cov=False )\n",
    "        self.loss_Matern = mse_loss(torch.from_numpy(y_test_gp),torch.from_numpy(y_predict_gp))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_Matern.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        predict = gp.predict(x_input,return_std=False, return_cov=False )\n",
    "        predict = (predict * self.y_train_std[0]) + self.y_train_mean[0]\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "      \n",
    "    def on_clicked_Sum_RBF(self):\n",
    "        y_train_gp = self.y_train_[:,0]\n",
    "        y_test_gp =self.y_test_[:,0]\n",
    "        gp=GPR()\n",
    "        gp.__init__(kernel='Sum_RBF', noise=1e-10,optimizer='fmin_l_bfgs_b',n_restarts_optimizer=10, porder=2)\n",
    "        gp.fit(self.x_train_,y_train_gp,iprint=True)\n",
    "        y_predict_gp, std_gp =gp.predict(self.x_test_,return_std=True, return_cov=False )\n",
    "        self.loss_Sum_RBF = mse_loss(torch.from_numpy(y_test_gp),torch.from_numpy(y_predict_gp))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_Sum_RBF.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        predict = gp.predict(x_input,return_std=False, return_cov=False )\n",
    "        predict = (predict * self.y_train_std[0]) + self.y_train_mean[0]\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "      \n",
    "    def on_clicked_Sum_RQ(self):\n",
    "        y_train_gp = self.y_train_[:,0]\n",
    "        y_test_gp = self.y_test_[:,0]\n",
    "        gp=GPR()\n",
    "        gp.__init__(kernel='Sum_RQ', noise=1e-10,optimizer='fmin_l_bfgs_b',n_restarts_optimizer=10, porder=2)\n",
    "        gp.fit(self.x_train_,y_train_gp,iprint=True)\n",
    "        y_predict_gp, std_gp =gp.predict(self.x_test_,return_std=True, return_cov=False )\n",
    "        self.loss_Sum_RQ = mse_loss(torch.from_numpy(y_test_gp),torch.from_numpy(y_predict_gp))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_Sum_RQ.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_input using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        predict = gp.predict(x_input,return_std=False, return_cov=False )\n",
    "        predict = (predict * self.y_train_std[0]) + self.y_train_mean[0]\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "      \n",
    "    def on_clicked_two(self):\n",
    "        import gpflux\n",
    "        import gpflow\n",
    "        import tensorflow as tf\n",
    "        X = self.x_train_\n",
    "        Y = self.y_train_\n",
    "\n",
    "        # Layer 1\n",
    "        Z = np.linspace(X.min(), X.max(), X.shape[0] // 2).reshape(-1, 2)\n",
    "        kernel1 = gpflow.kernels.SquaredExponential()\n",
    "        inducing_variable1 = gpflow.inducing_variables.InducingPoints(Z.copy())\n",
    "        gp_layer1 = gpflux.layers.GPLayer(\n",
    "            kernel1, inducing_variable1, num_data=X.shape[0],num_latent_gps=2)\n",
    "\n",
    "        # Layer 2\n",
    "        kernel2 = gpflow.kernels.RationalQuadratic()\n",
    "        inducing_variable2 = gpflow.inducing_variables.InducingPoints(Z.copy())\n",
    "        gp_layer2 = gpflux.layers.GPLayer(\n",
    "           kernel2,\n",
    "           inducing_variable2,\n",
    "           num_data=X.shape[0],\n",
    "           num_latent_gps=12,\n",
    "           mean_function=gpflow.mean_functions.Zero(),\n",
    "        )\n",
    "\n",
    "        # Initialise likelihood and build model\n",
    "        likelihood_layer = gpflux.layers.LikelihoodLayer(gpflow.likelihoods.Gaussian(0.1))\n",
    "        self.two_layer_dgp = gpflux.models.DeepGP([gp_layer1, gp_layer2], likelihood_layer)\n",
    "\n",
    "        # Compile and fit\n",
    "        model = self.two_layer_dgp.as_training_model()\n",
    "        model.compile(tf.optimizers.Adam(0.01))\n",
    "        history = model.fit({\"inputs\": X, \"targets\": Y}, epochs=int(1e2), verbose=0)\n",
    "        \n",
    "        mean_prediction_dgpc= model.predict({\"inputs\": self.x_test_, \"targets\": np.zeros_like(self.y_test_)})\n",
    "        self.loss_two= mse_loss(torch.from_numpy(mean_prediction_dgpc),torch.from_numpy(self.y_test_))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_two.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_test using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        x_input_shape = np.shape(x_input)\n",
    "        predict= model.predict({\"inputs\": x_input, \"targets\": np.zeros((x_input_shape[0],12))})\n",
    "        predict = (predict * self.y_train_std) + self.y_train_mean\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_opti_Two(self):\n",
    "        self.dgp_2 = self.two_layer_dgp.as_prediction_model()\n",
    "        input_text_indiv= self.ui.lineEdit_num_indiv.text()\n",
    "        num_of_individuals = ast.literal_eval(input_text_indiv)\n",
    "        input_text_gen= self.ui.lineEdit_num_gen.text()\n",
    "        num_of_generations = ast.literal_eval(input_text_gen)\n",
    "        self.opti_two = OptimisationProblem(self.dgp_2, model = 'DeepGP')\n",
    "        result = self.opti_two.solve(bounds =[(-1.8,1.8), (-1.8,1.8)], num_of_individuals = num_of_individuals, num_of_generations = num_of_generations )\n",
    "        result_array = np.array(result[1])\n",
    "        result_reshaped= result_array.reshape(1  ,-1)\n",
    "        true_result = self.scaler.inverse_transform(result_reshaped)\n",
    "        result_predict = np.array(result[-1])\n",
    "        result_predict_reshaped = result_predict.reshape(1,-1) \n",
    "        true_predict = self.scaler_y.inverse_transform(result_predict_reshaped)\n",
    "        true_objective = self.price_biogas*(true_predict[0,3]+true_predict[0,4])+self.price_sludge_TP*true_predict[0,8]+self.price_sludge_TN*true_predict[0,7]-(true_predict[0,9]+true_predict[0,10])\n",
    "        self.ui.label_results_opti.setText(\"The optimal individuals and objective function are: \" + str(true_result)+\", \" + str(true_objective))\n",
    "    \n",
    "    def on_clicked_three(self):\n",
    "        import gpflux\n",
    "        import gpflow\n",
    "        import tensorflow as tf\n",
    "        X = self.x_train_\n",
    "        Y = self.y_train_\n",
    "        \n",
    "        # Layer 1\n",
    "        Z = np.linspace(X.min(), X.max(), X.shape[0] // 2).reshape(-1, 2)\n",
    "        kernel1 = gpflow.kernels.SquaredExponential()\n",
    "        inducing_variable1 = gpflow.inducing_variables.InducingPoints(Z.copy())\n",
    "        gp_layer1 = gpflux.layers.GPLayer(\n",
    "           kernel1, inducing_variable1, num_data=X.shape[0],num_latent_gps=2)\n",
    "\n",
    "        # Layer 2\n",
    "        kernel2 = gpflow.kernels.RationalQuadratic()\n",
    "        inducing_variable2 = gpflow.inducing_variables.InducingPoints(Z.copy())\n",
    "        gp_layer2 = gpflux.layers.GPLayer(\n",
    "           kernel2,\n",
    "           inducing_variable2,\n",
    "           num_data=X.shape[0],\n",
    "           num_latent_gps=2,\n",
    "        )\n",
    "        # Layer 3\n",
    "        kernel3 = gpflow.kernels.RationalQuadratic()\n",
    "        inducing_variable3 = gpflow.inducing_variables.InducingPoints(Z.copy())\n",
    "        gp_layer3= gpflux.layers.GPLayer(\n",
    "           kernel3,\n",
    "           inducing_variable3,\n",
    "           num_data=X.shape[0],\n",
    "           num_latent_gps=12,\n",
    "           mean_function=gpflow.mean_functions.Zero(),\n",
    "        )\n",
    "\n",
    "        # Initialise likelihood and build model\n",
    "        likelihood_layer_2 = gpflux.layers.LikelihoodLayer(gpflow.likelihoods.Gaussian(0.1))\n",
    "        self.three_layer_dgp = gpflux.models.DeepGP([gp_layer1, gp_layer2,gp_layer3], likelihood_layer_2)\n",
    "\n",
    "        # Compile and fit\n",
    "        model = self.three_layer_dgp.as_training_model()\n",
    "        model.compile(tf.optimizers.Adam(0.01))\n",
    "        history_2 = model.fit({\"inputs\": X, \"targets\": Y}, epochs=int(1e3), verbose=0)\n",
    "        \n",
    "        mean_prediction_dgpc= model.predict({\"inputs\": self.x_test_, \"targets\": np.zeros_like(self.y_test_)})\n",
    "        self.loss_three= mse_loss(torch.from_numpy(mean_prediction_dgpc),torch.from_numpy(self.y_test_))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_three.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_test using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        x_input_shape = np.shape(x_input)\n",
    "        predict= model.predict({\"inputs\": x_input, \"targets\": np.zeros((x_input_shape[0],12))})\n",
    "        predict = (predict * self.y_train_std) + self.y_train_mean\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_opti_Three(self):\n",
    "        self.dgp_3 = self.three_layer_dgp.as_prediction_model()\n",
    "        input_text_indiv= self.ui.lineEdit_num_indiv.text()\n",
    "        num_of_individuals = ast.literal_eval(input_text_indiv)\n",
    "        input_text_gen= self.ui.lineEdit_num_gen.text()\n",
    "        num_of_generations = ast.literal_eval(input_text_gen)\n",
    "        self.opti_three = OptimisationProblem(self.dgp_3, model = 'DeepGP')\n",
    "        result = self.opti_three.solve(bounds =[(-1,1.8), (-1.8,1.8)], num_of_individuals = num_of_individuals, num_of_generations = num_of_generations )\n",
    "        result_array = np.array(result[1])\n",
    "        result_reshaped= result_array.reshape(1  ,-1)\n",
    "        true_result = self.scaler.inverse_transform(result_reshaped)\n",
    "        result_predict = np.array(result[-1])\n",
    "        result_predict_reshaped = result_predict.reshape(1,-1) \n",
    "        true_predict = self.scaler_y.inverse_transform(result_predict_reshaped)\n",
    "        true_objective = self.price_biogas*(true_predict[0,3]+true_predict[0,4])+self.price_sludge_TP*true_predict[0,8]+self.price_sludge_TN*true_predict[0,7]-(true_predict[0,9]+true_predict[0,10])\n",
    "        self.ui.label_results_opti.setText(\"The optimal individuals and objective function are: \" + str(true_result)+\", \" + str(true_objective))\n",
    "        \n",
    "    def on_clicked_four(self):\n",
    "        import gpflux\n",
    "        import gpflow\n",
    "        import tensorflow as tf\n",
    "        X = self.x_train_\n",
    "        Y = self.y_train_\n",
    "        \n",
    "        # Layer 1\n",
    "        Z = np.linspace(X.min(), X.max(), X.shape[0] // 2).reshape(-1, 2)\n",
    "        kernel1 = gpflow.kernels.SquaredExponential()\n",
    "        inducing_variable1 = gpflow.inducing_variables.InducingPoints(Z.copy())\n",
    "        gp_layer1 = gpflux.layers.GPLayer(\n",
    "           kernel1, inducing_variable1, num_data=X.shape[0],num_latent_gps=2)\n",
    "\n",
    "        # Layer 2\n",
    "        kernel2 = gpflow.kernels.SquaredExponential()\n",
    "        inducing_variable2 = gpflow.inducing_variables.InducingPoints(Z.copy())\n",
    "        gp_layer2 = gpflux.layers.GPLayer(\n",
    "           kernel2,\n",
    "           inducing_variable2,\n",
    "           num_data=X.shape[0],\n",
    "           num_latent_gps=2,\n",
    "        )\n",
    "        # Layer 3\n",
    "        kernel3 = gpflow.kernels.SquaredExponential()\n",
    "        inducing_variable3 = gpflow.inducing_variables.InducingPoints(Z.copy())\n",
    "        gp_layer3= gpflux.layers.GPLayer(\n",
    "           kernel3,\n",
    "           inducing_variable3,\n",
    "           num_data=X.shape[0],\n",
    "           num_latent_gps=2,\n",
    "        )\n",
    "        # layer 4\n",
    "        kernel4 = gpflow.kernels.RationalQuadratic()\n",
    "        inducing_variable4 = gpflow.inducing_variables.InducingPoints(Z.copy())\n",
    "        gp_layer4= gpflux.layers.GPLayer(\n",
    "           kernel4,\n",
    "           inducing_variable4,\n",
    "           num_data=X.shape[0],\n",
    "           num_latent_gps=12,\n",
    "           mean_function=gpflow.mean_functions.Zero(),\n",
    "        )\n",
    "        # Initialise likelihood and build model\n",
    "        likelihood_layer_4 = gpflux.layers.LikelihoodLayer(gpflow.likelihoods.Gaussian(0.1))\n",
    "        self.four_layer_dgp = gpflux.models.DeepGP([gp_layer1, gp_layer2,gp_layer3,gp_layer4], likelihood_layer_4)\n",
    "\n",
    "        # Compile and fit\n",
    "        model = self.four_layer_dgp.as_training_model()\n",
    "        model.compile(tf.optimizers.Adam(0.01))\n",
    "        history_4 = model.fit({\"inputs\": X, \"targets\": Y}, epochs=int(1e3), verbose=0)\n",
    "        \n",
    "        mean_prediction_dgpc= model.predict({\"inputs\": self.x_test_, \"targets\": np.zeros_like(self.y_test_)})\n",
    "        self.loss_four= mse_loss(torch.from_numpy(mean_prediction_dgpc),torch.from_numpy(self.y_test_))\n",
    "        self.ui.label_loss.setText(\"the MSE loss is: \" + str(self.loss_four.item()))\n",
    "        \n",
    "        input_text = self.ui.lineEdit.text()\n",
    "        input_values = ast.literal_eval(input_text)\n",
    "        x_input = np.array(input_values, dtype=float).reshape(-1, 2)\n",
    "        # normalise x_test using training moments\n",
    "        x_input = (x_input - self.x_train_mean) / self.x_train_std\n",
    "        x_input_shape = np.shape(x_input)\n",
    "        predict= model.predict({\"inputs\": x_input, \"targets\": np.zeros((x_input_shape[0],12))})\n",
    "        predict = (predict * self.y_train_std) + self.y_train_mean\n",
    "        self.ui.label_predict.setText(\"The predicted ouput vector is: \" + str(predict))\n",
    "        \n",
    "    def on_clicked_opti_Four(self):\n",
    "        self.dgp_4 = self.four_layer_dgp.as_prediction_model()\n",
    "        input_text_indiv= self.ui.lineEdit_num_indiv.text()\n",
    "        num_of_individuals = ast.literal_eval(input_text_indiv)\n",
    "        input_text_gen= self.ui.lineEdit_num_gen.text()\n",
    "        num_of_generations = ast.literal_eval(input_text_gen)\n",
    "        self.opti_four = OptimisationProblem(self.dgp_4, model = 'DeepGP')\n",
    "        result = self.opti_four.solve(bounds =[(-1.8,1.8), (-1.8,1.8)], num_of_individuals = num_of_individuals, num_of_generations = num_of_generations )\n",
    "        result_array = np.array(result[1])\n",
    "        result_reshaped= result_array.reshape(1  ,-1)\n",
    "        true_result = self.scaler.inverse_transform(result_reshaped)\n",
    "        result_predict = np.array(result[-1])\n",
    "        result_predict_reshaped = result_predict.reshape(1,-1) \n",
    "        true_predict = self.scaler_y.inverse_transform(result_predict_reshaped)\n",
    "        true_objective = self.price_biogas*(true_predict[0,3]+true_predict[0,4])+self.price_sludge_TP*true_predict[0,8]+self.price_sludge_TN*true_predict[0,7]-(true_predict[0,9]+true_predict[0,10])\n",
    "        self.ui.label_results_opti.setText(\"The optimal individuals and objective function are: \" + str(true_result)+\", \" + str(true_objective))\n",
    "        \n",
    "    def bar_chart(self):\n",
    "\n",
    "        categories = ['RQ','ReLu','Leaky ReLu','Swish','SP','Sigmoid','Serf','Linear', 'RBF', 'Poly','ESS','Matern','Sum RBF','Sum RQ','two','Three','Four']\n",
    "        values = [self.loss_RQ, self.loss_ReLu,self.loss_Leaky_ReLu,self.loss_swish,self.loss_softplus,self.loss_Sigmoid,self.loss_serf,self.loss_Linear,self.loss_RBF,self.loss_Poly,self.loss_ESS,self.loss_Matern,self.loss_Sum_RBF,self.loss_Sum_RQ,self.loss_two, self.loss_three, self.loss_four]\n",
    "        fig, ax =  plt.subplots(layout = 'constrained')\n",
    "        ax.bar(categories, values)\n",
    "        canvas = FigureCanvas(fig)\n",
    "        plt.xlabel('Categories')\n",
    "        plt.ylabel('Values')\n",
    "        plt.title('Mean Squared errors')\n",
    "        \n",
    "        self.show_window= graph_window(fig, 'loss')\n",
    "        self.show_window.show()\n",
    "        \n",
    "        \n",
    "class graph_window(QMainWindow):\n",
    "    def __init__(self,fig,name):\n",
    "        super().__init__()\n",
    "            \n",
    "        dw = QGuiApplication.primaryScreen().size()\n",
    "        self.resize(int(dw.width()*0.7), int(dw.height()*0.7))\n",
    "        self.setWindowTitle('losses' +name)\n",
    "        layout= QGridLayout()    \n",
    "        canvas = FigureCanvas(fig)\n",
    "        layout.addWidget(canvas,0,0)\n",
    "           \n",
    "        central_widget = QWidget(self)\n",
    "        central_widget.setLayout(layout)\n",
    "        self.setCentralWidget(central_widget)\n",
    "            \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7f555c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "app = QtWidgets.QApplication([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "884ed6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = MainWindow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7faac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "window.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a74e2efd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072d8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d640a01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad70fa51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
